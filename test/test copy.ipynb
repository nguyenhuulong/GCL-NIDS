{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dglnn\n",
    "import dgl\n",
    "import math\n",
    "from dgl import from_networkx\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import socket\n",
    "import struct\n",
    "import random \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import os\n",
    "import torch.nn.init as init\n",
    "from dgl.nn import GATConv\n",
    "from dgl.nn.functional import edge_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('NF-BoT-IoT-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['IPV4_DST_ADDR'] = data.IPV4_DST_ADDR.apply(lambda x: socket.inet_ntoa(struct.pack('>I', random.randint(0xac100001, 0xac1f0001))))\n",
    "data['IPV4_SRC_ADDR'] = data.IPV4_SRC_ADDR.apply(str)\n",
    "data['L4_SRC_PORT'] = data.L4_SRC_PORT.apply(str)\n",
    "data['IPV4_DST_ADDR'] = data.IPV4_DST_ADDR.apply(str)\n",
    "data['L4_DST_PORT'] = data.L4_DST_PORT.apply(str)\n",
    "data['IPV4_SRC_ADDR'] = data['IPV4_SRC_ADDR'] + ':' + data['L4_SRC_PORT']\n",
    "data['IPV4_DST_ADDR'] = data['IPV4_DST_ADDR'] + ':' + data['L4_DST_PORT']\n",
    "data.drop(columns=['L4_SRC_PORT','L4_DST_PORT'],inplace=True)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.Attack.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca76855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Label'],inplace = True)\n",
    "data.rename(columns={\"Attack\": \"label\"},inplace = True)\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(data.label.values)\n",
    "data['label'] = le.transform(data['label'])\n",
    "label = data.label\n",
    "data.drop(columns=['label'],inplace = True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "data =  pd.concat([data, label], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,label, test_size=0.3, random_state=123,stratify= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe77e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL'])\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train = encoder.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns ))  - set(list(['label'])) )\n",
    "X_train[cols_to_norm] = scaler.fit_transform(X_train[cols_to_norm])\n",
    "\n",
    "X_train['h'] = X_train[ cols_to_norm ].values.tolist()\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb1ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, in_features, out_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h_u = edges.src['h']\n",
    "        h_v = edges.dst['h']\n",
    "        score = self.W(th.cat([h_u, h_v], 1))\n",
    "        return {'score': score}\n",
    "\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(self.apply_edges)\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07908e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATlayer(nn.Module):\n",
    "    def __init__(self, n_feat, e_feat, out_feat, num_heads):\n",
    "        super(GATlayer,self).__init__()\n",
    "    \n",
    "        self.n_feat = n_feat\n",
    "        self.e_feat = e_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.num_heads = num_heads\n",
    "        self.W_msg = nn.Linear(2 * n_feat + e_feat, out_feat)\n",
    "        self.W = nn.Linear(2 * n_feat + e_feat, 2 * out_feat)\n",
    " \n",
    "        self.a = nn.Parameter(torch.rand(size=(2 * out_feat  , 1)))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        gain = math.sqrt(2)\n",
    "        init.xavier_normal_(self.W.weight, gain=gain)\n",
    "\n",
    "        init.xavier_normal_(self.a, gain=gain)\n",
    "    \n",
    "    def edge_attention(self, edges):        \n",
    "        \n",
    "        feat_cat = torch.cat([edges.src['h'], edges.dst['h'], edges.data['h']], dim=1)\n",
    "        \n",
    "        w_feat_cat = self.W(feat_cat)\n",
    "                \n",
    "        #e = F.leaky_relu(torch.matmul(w_feat_cat, self.a[i]))\n",
    "                              \n",
    "        return {'e': F.leaky_relu(torch.matmul(w_feat_cat, self.a))}\n",
    "        \n",
    "#     def message_func(self, edges):\n",
    "#         return {'h': self.W_msg(torch.cat([edges.src['h'], edges.dst['h'], edges.data['h']], dim=1)) , 'e': edges.data['e']}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'h': self.W_msg(torch.cat([edges.src['h'], edges.dst['h'], edges.data['h']], dim=1)) , 'x': edges.data['x']}\n",
    "  \n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        \n",
    "#         attention = F.softmax(nodes.mailbox['e'] ,dim = 1)\n",
    "#         h = (attention * nodes.mailbox['h']).sum(1)\n",
    "        h = (nodes.mailbox['x'] * nodes.mailbox['h']).sum(1)\n",
    "        return {'h': h}\n",
    "    \n",
    "    def forward(self, g, n_feat, e_feat):\n",
    "        with g.local_scope():\n",
    "            \n",
    "            g.ndata['h'] = n_feat\n",
    "            \n",
    "            g.edata['h'] = e_feat\n",
    "            g.apply_edges(self.edge_attention)\n",
    "            #attention = edge_softmax(g, edges.data['e'] ,norm_by='src')\n",
    "            attention = edge_softmax(g, g.edata['e'])\n",
    "            g.edata['x'] = attention\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            g.ndata['h'] = F.relu(g.ndata['h'])\n",
    "            feat = g.ndata['h']\n",
    "                \n",
    "            return feat\n",
    "        \n",
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, n_feat, e_feat, out_feat, num_heads):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATlayer(n_feat, e_feat, out_feat, num_heads))\n",
    "        \n",
    "    def forward(self,g, h, e_feat):\n",
    "        \n",
    "        out_feat = [attn_head(g, h, e_feat) for attn_head in self.heads]\n",
    "    \n",
    "        out_feat = torch.cat(out_feat,dim = 1).reshape(g.num_nodes(),len(self.heads), -1)\n",
    "\n",
    "        return out_feat.mean(1)\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_dim, e_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer( in_dim, e_dim, 39, num_heads)\n",
    "#         self.layer1 = MultiHeadGATLayer( in_dim, e_dim, 16, num_heads)\n",
    "#         self.layer2 = MultiHeadGATLayer( 16, e_dim, out_dim, 1)\n",
    "        \n",
    "    def forward(self, g, h, e_feat):\n",
    "        h = self.layer1(g, h, e_feat)\n",
    "#         h = F.dropout(h,p = 0.2)\n",
    "#         h = self.layer2(g, h, e_feat)\n",
    "        g.ndata['h'] = h\n",
    "        return h , g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genetation(torch.nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, num_heads, activation):\n",
    "        super(Genetation, self).__init__()\n",
    "        self.conv = GATConv(in_feat, out_feat, num_heads)\n",
    "        self.activation = activation\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, g, feat):\n",
    "        x = self.activation(self.conv(g, feat))\n",
    "        #x = self.conv(g, feat)\n",
    "        g.ndata['h'] = x\n",
    "        return x.mean(1) ,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sub_sam(nodes, adj_lists, k):\n",
    "    node_neighbor =  [ [] for i in range(nodes.shape[0])]\n",
    "    node_neighbor_cen =  [ [] for i in range(nodes.shape[0])]\n",
    "    node_centorr =  [[] for i in range(nodes.shape[0])]\n",
    "\n",
    "    num_nei = 0\n",
    "\n",
    "    for node in nodes:\n",
    "        neighbors = set([int(node)])\n",
    "        neighs = adj_lists[int(node)]\n",
    "        node_centorr[num_nei] = [int(node)]\n",
    "        current1 = adj_lists[int(node)]\n",
    "        if len(neighs) >= k:\n",
    "            neighs -= neighbors\n",
    "            current1 = random.sample(neighs, k-1)\n",
    "\n",
    "            node_neighbor[num_nei] = [neg_node for neg_node in current1]\n",
    "            current1.append(int(node))\n",
    "            node_neighbor_cen[num_nei] = [neg_node for neg_node in current1]\n",
    "            num_nei += 1\n",
    "\n",
    "        node_neighbor_cen[num_nei] = [neg_node for neg_node in current1]\n",
    "\n",
    "    node_neighbor_cen = [neighbors for neighbors in node_neighbor_cen if neighbors]\n",
    "    node_neighbor_cen  = node_neighbor_cen[:-1]\n",
    "    return node_neighbor_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,  Encoder, gene, tau = 0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = Encoder\n",
    "        self.tau: float = tau\n",
    "        self.ge = gene\n",
    "\n",
    "    def forward(self, graph, node_feats, edge_feats) :\n",
    "        z, g1 = self.encoder(graph,node_feats,edge_feats)\n",
    "        #z_g, g2 = self.ge(graph,z)\n",
    "        z_g, g2 = self.ge(graph,z,edge_feats)\n",
    "        return z, z_g, g1, g2\n",
    "    \n",
    "    def embed(self, graph, node_feats, edge_feats):\n",
    "        z,_ = self.encoder(graph, node_feats, edge_feats)\n",
    "        return z\n",
    "\n",
    "    def loss(self, z1, z2, adj, sub_g1, g1, g2):\n",
    "        loss = self.sub_loss_batch(z1, z2, adj, sub_g1, g1, g2)\n",
    "        return loss\n",
    "\n",
    "    def sub_loss_batch(self, z, z_g, adj, sub_g1, g1, g2):\n",
    "        subz_s, sub_gene_s = self.subg_centor(z, z_g, sub_g1)\n",
    "\n",
    "        num = th.randint(0, len(sub_g1)-1, [len(sub_g1),])\n",
    "        if num[0] == 0:\n",
    "            num[0] = 1\n",
    "        for i in range(1, len(num)):\n",
    "            if num[i] == i:\n",
    "                num[i] -= 1\n",
    "        subg2_s_n = subz_s[num] # disrupt\n",
    "        sub_gene_s_n = sub_gene_s[num]\n",
    "        #print('sub_gene_s',sub_gene_s.shape)\n",
    "        #print('sub_gene_s_n',sub_gene_s_n.shape)\n",
    "\n",
    "        input1 = th.cat((subz_s, subz_s, subz_s), dim=0)\n",
    "        input2 = th.cat((sub_gene_s, subg2_s_n, sub_gene_s_n), dim=0)\n",
    "        \n",
    "        edges1, edges2 = self.edges_f(g1, g2, sub_g1, z, z_g)\n",
    "        #print('edges2',edges2.shape)\n",
    "        subg2_se = edges1[num]\n",
    "        sub_gene_s_e = edges2[num]\n",
    "        #print('sub_gene_s_e',sub_gene_s_e.shape)\n",
    "        input1_edges = th.cat((edges1, edges1, edges1), dim=0)\n",
    "        input2_edges = th.cat((edges2, subg2_se, sub_gene_s_e), dim=0)\n",
    "        input1_edges = input1_edges.requires_grad_(True)\n",
    "        input2_edges = input2_edges.requires_grad_(True)\n",
    "        \n",
    "        # adj\n",
    "        subg1_adj = self.sub_adj(adj, sub_g1)\n",
    "        input_adj = th.cat((subg1_adj, subg1_adj, subg1_adj), dim=0)\n",
    "        \n",
    "        lbl_1 = th.ones(len(sub_g1)).cuda()\n",
    "        lbl_2 = th.zeros(len(sub_g1)*2).cuda()\n",
    "        lbl = th.cat((lbl_1, lbl_2), 0).cuda()\n",
    "        \n",
    "        lbl_1_e = th.ones(len(edges2) ).cuda()\n",
    "        lbl_2_e = th.zeros(len(edges2)* 2).cuda()\n",
    "        lbl_e = th.cat((lbl_1_e, lbl_2_e), 0).cuda()\n",
    "        \n",
    "         # WD\n",
    "        wd, T_wd = self.wd(input1, input2, self.tau)\n",
    "        logits = th.exp(-wd / 0.01)\n",
    "        loss1 = b_xent(th.squeeze(logits), lbl)\n",
    "        print('loss1', loss1)\n",
    "        \n",
    "        # GWD\n",
    "        gwd = self.gwd(input1.transpose(2,1), input2.transpose(2,1), T_wd, input_adj, self.tau)\n",
    "        logits2 = th.exp(-gwd / 0.1)\n",
    "        loss2 = b_xent(th.squeeze(logits2), lbl)\n",
    "        print('loss2',loss2)\n",
    "        \n",
    "\n",
    "        wd, T_wd = self.wd(input1_edges, input2_edges, self.tau)\n",
    "        logits3 = th.exp(-wd / 0.01)\n",
    "        loss3 = b_xent(th.squeeze(logits3), lbl_e)\n",
    "        print('loss3', loss3)\n",
    "\n",
    "\n",
    "        loss = 0.5 * loss3 + 0.5 * loss2\n",
    "        #loss = 0.6 * loss3 + 0.4 * loss1 \n",
    "        return loss\n",
    "    \n",
    "    def edges_f (self,g1,g2,sub_g1, z, z_g):\n",
    "        edge_feat_1 = [[] for i in range(len(sub_g1))]\n",
    "        edge_feat_2 = [[] for i in range(len(sub_g1))]\n",
    "        sc = MLPPredictor(g1.edata['h'].shape[1],39).cuda()\n",
    "        z_e = sc(g1, z)\n",
    "        z_ge = sc(g2, z_g)\n",
    "        for i in range(len(sub_g1)):\n",
    "            cen_node = sub_g1[i][-1]\n",
    "            dst = sub_g1[i][:-1]\n",
    "            src_node_id = cen_node\n",
    "\n",
    "            for j in dst:\n",
    "                dst_node_id = j\n",
    "\n",
    "                edge_indices = g1.edge_ids(src_node_id, dst_node_id,return_uv = True)\n",
    "\n",
    "                edge_feature_1 = torch.Tensor(z_e[edge_indices[2]]).float().tolist()\n",
    "                edge_feature_2 = torch.Tensor(z_ge[edge_indices[2]]).float().tolist()\n",
    "\n",
    "                edge_feat_1.append(edge_feature_1)\n",
    "                edge_feat_2.append(edge_feature_2)\n",
    "                if len(edge_feat_1[-1]) == 2:\n",
    "                    edge_feat_1[-1] = [edge_feat_1[-1][0]]\n",
    "                    edge_feat_2[-1] = [edge_feat_2[-1][0]]\n",
    "                \n",
    "        edge_feat_1 = [neighbors for neighbors in edge_feat_1 if neighbors]\n",
    "        edge_feat_2 = [neighbors for neighbors in edge_feat_2 if neighbors]\n",
    "        edge_feat_1 = torch.Tensor(edge_feat_1)\n",
    "#         print('edge_feat_1',edge_feat_1)\n",
    "        edge_feat_2 = torch.Tensor(edge_feat_2)\n",
    "        edge_feat_1 = edge_feat_1.reshape(len(sub_g1),-1, 39)\n",
    "        edge_feat_2 = edge_feat_2.reshape(len(sub_g1),-1, 39)\n",
    "        return edge_feat_1, edge_feat_2\n",
    "    \n",
    "    def sub_adj(self, adj, sub_g1):\n",
    "        subg1_adj = th.zeros(len(sub_g1), len(sub_g1[0]), len(sub_g1[0]))\n",
    "        for i in range(len(sub_g1)):\n",
    "            subg1_adj[i] = adj[sub_g1[i]].t()[sub_g1[i]]\n",
    "        return subg1_adj\n",
    "\n",
    "\n",
    "    def subg_centor(self, z, z_g, sub_g1):\n",
    "        sub = [element for lis in sub_g1 for element in lis]\n",
    "        subz = z[sub] \n",
    "        subg = z_g[sub]\n",
    "\n",
    "        sub_s = subz.reshape(len(sub_g1), len(sub_g1[0]), -1)\n",
    "        subg_s = subg.reshape(len(sub_g1), len(sub_g1[0]), -1)\n",
    "        return sub_s, subg_s\n",
    "\n",
    "    # WD\n",
    "    def wd(self, x, y, tau):\n",
    "        cos_distance = self.cost_matrix_batch(th.transpose(x, 2, 1), th.transpose(y, 2, 1), tau)\n",
    "        cos_distance = cos_distance.transpose(1,2)\n",
    "\n",
    "        beta = 0.1\n",
    "        min_score = cos_distance.min()\n",
    "        max_score = cos_distance.max()\n",
    "        threshold = min_score + beta * (max_score - min_score)\n",
    "        cos_dist = nn.functional.relu(cos_distance - threshold)\n",
    "        \n",
    "        wd, T_wd = self.OT_distance_batch(cos_dist, x.size(0), x.size(1), y.size(1), 40)\n",
    "        return wd, T_wd\n",
    "\n",
    "    def OT_distance_batch(self, C, bs, n, m, iteration=50):\n",
    "        C = C.float().cuda()\n",
    "        T = self.OT_batch(C, bs, n, m, iteration=iteration)\n",
    "        temp = th.bmm(th.transpose(C,1,2), T)\n",
    "        distance = self.batch_trace(temp, m, bs)\n",
    "        return distance, T\n",
    "    \n",
    "    def OT_batch(self, C, bs, n, m, beta=0.5, iteration=50):\n",
    "        sigma = th.ones(bs, int(m), 1).cuda()/float(m)\n",
    "        T = th.ones(bs, n, m).cuda()\n",
    "        A = th.exp(-C/beta).float().cuda()\n",
    "        for t in range(iteration):\n",
    "            Q = A * T\n",
    "            for k in range(1):\n",
    "                delta = 1 / (n * th.bmm(Q, sigma))\n",
    "                a = th.bmm(th.transpose(Q,1,2), delta)\n",
    "                sigma = 1 / (float(m) * a)\n",
    "            T = delta * Q * sigma.transpose(2,1)\n",
    "        return T\n",
    "\n",
    "    def cost_matrix_batch(self, x, y, tau=0.5):\n",
    "        bs = list(x.size())[0]\n",
    "        D = x.size(1)\n",
    "        assert(x.size(1)==y.size(1))\n",
    "        x = x.contiguous().view(bs, D, -1)\n",
    "        x = x.div(th.norm(x, p=2, dim=1, keepdim=True) + 1e-12)\n",
    "        y = y.div(th.norm(y, p=2, dim=1, keepdim=True) + 1e-12)\n",
    "        \n",
    "        cos_dis = th.bmm(th.transpose(x, 1, 2), y)\n",
    "        cos_dis = th.exp(- cos_dis / tau)\n",
    "        return cos_dis.transpose(2,1)\n",
    "\n",
    "    def batch_trace(self, input_matrix, n, bs):\n",
    "        a = th.eye(n).cuda().unsqueeze(0).repeat(bs, 1, 1)\n",
    "        b = a * input_matrix\n",
    "        return th.sum(th.sum(b,-1),-1).unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    # GWD\n",
    "    def gwd(self, X, Y, T_wd, input_adj, tau, lamda=1e-1, iteration=5, OT_iteration=20):\n",
    "        m = X.size(2)\n",
    "        n = Y.size(2)\n",
    "        bs = X.size(0)\n",
    "        p = (th.ones(bs, m, 1)/m).cuda()\n",
    "        q = (th.ones(bs, n, 1)/n).cuda()\n",
    "        return self.GW_distance(X, Y, p, q, T_wd, input_adj, tau, lamda=lamda, iteration=iteration, OT_iteration=OT_iteration)\n",
    "\n",
    "    def GW_distance(self, X, Y, p, q, T_wd, input_adj, tau, lamda=0.5, iteration=5, OT_iteration=20):\n",
    "        cos_dis = th.exp(- input_adj / tau).cuda() \n",
    "        beta = 0.1\n",
    "        min_score = cos_dis.min()\n",
    "        max_score = cos_dis.max()\n",
    "        threshold = min_score + beta * (max_score - min_score)\n",
    "        res = cos_dis - threshold\n",
    "        Cs = nn.functional.relu(res.transpose(2,1))\n",
    "\n",
    "        Ct = self.cos_batch(Y, Y, tau).float().cuda()\n",
    "        bs = Cs.size(0)\n",
    "        m = Ct.size(2)\n",
    "        n = Cs.size(2)\n",
    "        T, Cst = self.GW_batch(Cs, Ct, bs, n, m, p, q, beta=lamda, iteration=iteration, OT_iteration=OT_iteration)\n",
    "        temp = th.bmm(th.transpose(Cst,1,2), T_wd)\n",
    "        distance = self.batch_trace(temp, m, bs)\n",
    "        return distance\n",
    "\n",
    "    def GW_batch(self, Cs, Ct, bs, n, m, p, q, beta=0.5, iteration=5, OT_iteration=20):\n",
    "        one_m = th.ones(bs, m, 1).float().cuda()\n",
    "        one_n = th.ones(bs, n, 1).float().cuda()\n",
    "\n",
    "        Cst = th.bmm(th.bmm(Cs**2, p), th.transpose(one_m, 1, 2)) + \\\n",
    "            th.bmm(one_n, th.bmm(th.transpose(q,1,2), th.transpose(Ct**2, 1, 2)))\n",
    "        gamma = th.bmm(p, q.transpose(2,1))\n",
    "        for i in range(iteration):\n",
    "            C_gamma = Cst - 2 * th.bmm(th.bmm(Cs, gamma), th.transpose(Ct, 1, 2))\n",
    "            gamma = self.OT_batch(C_gamma, bs, n, m, beta=beta, iteration=OT_iteration)\n",
    "        Cgamma = Cst - 2 * th.bmm(th.bmm(Cs, gamma), th.transpose(Ct, 1, 2))\n",
    "        return gamma.detach(), Cgamma\n",
    "\n",
    "    def cos_batch(self, x, y, tau):\n",
    "        bs = x.size(0)\n",
    "        D = x.size(1)\n",
    "        assert(x.size(1)==y.size(1))\n",
    "        x = x.contiguous().view(bs, D, -1)\n",
    "        x = x.div(th.norm(x, p=2, dim=1, keepdim=True) + 1e-12)\n",
    "        y = y.div(th.norm(y, p=2, dim=1, keepdim=True) + 1e-12)\n",
    "        cos_dis = th.bmm(th.transpose(x,1,2), y)\n",
    "        cos_dis = th.exp(- cos_dis / tau).transpose(1,2)\n",
    "        \n",
    "        beta = 0.1\n",
    "        min_score = cos_dis.min()\n",
    "        max_score = cos_dis.max()\n",
    "        threshold = min_score + beta * (max_score - min_score)\n",
    "        res = cos_dis - threshold\n",
    "        return nn.functional.relu(res.transpose(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75393c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "\n",
    "X_test['h'] = X_test[ cols_to_norm ].values.tolist()\n",
    "G_test = nx.from_pandas_edgelist(X_test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", ['h','label'],create_using=nx.MultiGraph())\n",
    "G_test = G_test.to_directed()\n",
    "\n",
    "G_test = from_networkx(G_test,edge_attrs=['h','label'] )\n",
    "#actual = G_test.edata.pop('label')\n",
    "\n",
    "G_test.ndata['feature'] = th.ones(G_test.num_nodes(), G_test.edata['h'].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' \n",
    "G_test = G_test.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97451998",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 加载模型\n",
    "model = torch.load('model-botv2.pth')\n",
    "log = torch.load('log-botv2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "test_embs = model.embed(G_test,G_test.ndata['feature'],G_test.edata['h'])\n",
    "test_lbls = G_test.edata['label']\n",
    "\n",
    "\n",
    "logits = log(G_test, test_embs)\n",
    "preds = th.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.to('cpu')\n",
    "preds.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lbls = test_lbls.to('cpu')\n",
    "test_lbls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb67757",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lbls = le.inverse_transform(test_lbls)\n",
    "preds = le.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b679269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(cm = confusion_matrix(test_lbls, preds), \n",
    "                      normalize    = False,\n",
    "                      target_names = np.unique(test_lbls),\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lbls = list(test_lbls)\n",
    "preds = list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = np.unique(test_lbls)\n",
    "print(classification_report(test_lbls, preds, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = np.unique(test_lbls)\n",
    "print(classification_report(test_lbls, preds, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92610374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = np.unique(test_lbls)\n",
    "print(classification_report(test_lbls, preds, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86200dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
